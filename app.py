# app.py
import streamlit as st
import os
import time
import tempfile
from pathlib import Path
import logging
import json
import os
from datetime import datetime

# ====== å¯¼å…¥ä½ çš„çœŸå®æ¨¡å—(è¯·æ ¹æ®å®é™…è·¯å¾„è°ƒæ•´)======
from utils import (
    extract_frames,
    run_ocr,
    denoise_ocr,
    merge_text_across_frames_for_understanding,
    build_timeline,
    build_prompt
)
from llm_client import LLMClient



default_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ­è§†é¢‘å†…å®¹ç†è§£ä¸å®¡æ ¸æ¨¡å‹ã€‚
ä½ å°†åŸºäºè§†é¢‘ä¸­é€šè¿‡ OCR æå–çš„æ–‡å­—å†…å®¹ï¼Œå¯¹è§†é¢‘è¿›è¡Œå¤šç»´åº¦åˆ†æã€‚

ã€èƒŒæ™¯è¯´æ˜ã€‘
- ä»¥ä¸‹æ–‡å­—æŒ‰æ—¶é—´é¡ºåºæå–è‡ªè§†é¢‘ç”»é¢ï¼ˆåŒ…æ‹¬å­—å¹•ã€æ ‡é¢˜ã€æ°´å°ç­‰ï¼‰ã€‚
- è‹¥æŸæ–‡æœ¬åœ¨è¿ç»­æ—¶é—´æ®µé‡å¤å‡ºç°ï¼Œé€šå¸¸è¡¨ç¤ºå…¶ä¸ºæ ¸å¿ƒä¿¡æ¯æˆ–å›ºå®šæ ‡è¯†ã€‚
- æ–‡æœ¬å¯èƒ½åŒ…å«å£è¯­åŒ–è¡¨è¾¾ã€è¥é”€è¯æœ¯æˆ–ä¸å®Œæ•´å¥å­ï¼Œè¯·ç»“åˆæ•´ä½“è¯­å¢ƒç†è§£ã€‚

ã€è§†é¢‘æ–‡å­—æ—¶é—´è½´ã€‘
{timeline_text}

ã€åˆ†æä»»åŠ¡ã€‘
è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹å„é¡¹å®Œæˆåˆ†æï¼Œå¹¶ä»¥ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦ä»»ä½•é¢å¤–è¯´æ˜ï¼š

1. summary: ç”¨ä¸€å¥è¯æ¦‚æ‹¬è§†é¢‘ä¸»è¦å†…å®¹
2. summary_confidence:ç»™å‡ºæ‘˜è¦çš„ç½®ä¿¡åº¦(0-1)
3. tags: ç»™å‡º 3~5 ä¸ªå†…å®¹æ ‡ç­¾ï¼ˆå­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
4. category: å†…å®¹ç±»å‹ï¼ˆå¦‚ æ–°é—»ã€ä½“è‚²ã€å¨±ä¹ã€å¹¿å‘Š ç­‰ï¼‰
5. genre: å†…å®¹ä½“è£ï¼ˆå¦‚ èµ›äº‹æŠ¥é“ã€äººç‰©ç‰¹å†™ã€å¿«è®¯ ç­‰ï¼‰
6. tone: æ•´ä½“è°ƒæ€§ï¼ˆå¦‚ å®¢è§‚ã€ç…½æƒ…ã€å¹½é»˜ã€ä¸¥è‚ƒ ç­‰ï¼‰
7. sentiment: æƒ…æ„Ÿå€¾å‘ï¼ˆå¦‚ ç§¯æã€æ¶ˆæã€ä¸­æ€§ï¼‰
8. is_low_quality: æ˜¯å¦ä¸ºä½è´¨å†…å®¹ï¼ˆæ˜¯/å¦ï¼‰è‹¥æ˜¯è¯·æè¿°åŸå› 
9. has_risk: æ˜¯å¦å­˜åœ¨æ½œåœ¨è¿è§„é£é™©ï¼ˆæ˜¯/å¦ï¼‰è‹¥æ˜¯è¯·æè¿°åŸå› 

ã€è¾“å‡ºæ ¼å¼ã€‘
åªè¾“å‡ºä¸€ä¸ªåˆæ³• JSON å¯¹è±¡ï¼Œå­—æ®µåå¿…é¡»ä¸ºä¸Šè¿°è‹±æ–‡åã€‚"""
# ====== é¡µé¢é…ç½® ======
st.set_page_config(
    page_title="ğŸ¥ AI è§†é¢‘ç†è§£ç³»ç»Ÿ",
    layout="wide",
    initial_sidebar_state="collapsed"
)


# åˆ›å»º logs ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
os.makedirs("logs", exist_ok=True)

# é…ç½®æ—¥å¿—æ ¼å¼å’Œæ–‡ä»¶
log_filename = f"logs/analysis_{datetime.now().strftime('%Y%m%d')}.log"
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8'),
        logging.StreamHandler()  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°ï¼ˆå¯é€‰ï¼‰
    ]
)
logger = logging.getLogger(__name__)


def get_analysis_mode_config(mode: str):

    MODE_CONFIGS = {
        "å¿«é€Ÿæ‘˜è¦": {
            "sim_threshold": 0.92,      # é«˜ç›¸ä¼¼æ‰åˆå¹¶,ä¿ç•™å…³é”®ä¿¡æ¯
            "time_gap_merge": 6,        # è¾ƒé•¿é—´éš”,å‡å°‘ç‰‡æ®µæ•°é‡
            "interval_sec": 5,

        },
        "å…¨é¢åˆ†æ": {
            "sim_threshold": 0.85,      # ä¸­ç­‰ç›¸ä¼¼åº¦,å¹³è¡¡ç»†èŠ‚ä¸å†—ä½™
            "time_gap_merge": 3,        # é€‚ä¸­åˆå¹¶çª—å£
            "interval_sec": 3,

        },
        "å®¡æ ¸æ¨¡å¼": {
            "sim_threshold": 0.78,      # æ›´æ•æ„Ÿ,ä¿ç•™æ›´å¤šåŸæ–‡ç»†èŠ‚(é˜²æ¼æ£€)
            "time_gap_merge": 2,        # çŸ­é—´éš”,é¿å…è·¨é•œå¤´è¯¯åˆ
            "interval_sec": 1,
        },
        "è‡ªå®šä¹‰": {
            "sim_threshold": 0.90,      # é»˜è®¤å€¼,å®é™…ç”±å‰ç«¯ä¼ å‚è¦†ç›–(æ­¤å¤„ä»…å…œåº•)
            "time_gap_merge": 6,
            "interval_sec": 1,
        }
    }

    if mode not in MODE_CONFIGS:
        raise ValueError(f"ä¸æ”¯æŒçš„åˆ†ææ¨¡å¼: {mode}ã€‚å¯é€‰å€¼: {list(MODE_CONFIGS.keys())}")

    return MODE_CONFIGS[mode]
# ====== ä¸»ç•Œé¢ ======
st.title("ğŸ¥ AI è§†é¢‘å†…å®¹ç†è§£ç³»ç»Ÿ")
st.caption("æ”¯æŒå¤šæ¨¡æ€åˆ†æ Â· åŠ¨æ€ Prompt é…ç½® Â· å®æ—¶ç»“æ„åŒ–è¾“å‡º")

# ==============================
# ä¸‰æ å¸ƒå±€
# ==============================
col_left, col_middle, col_right = st.columns([5, 3.2, 4.3], gap="medium")
# --- å·¦ä¾§:è¾“å…¥æ§åˆ¶ ---
with col_left:
    with st.container(border=True, height=800):
        st.subheader("ğŸ› ï¸ è¾“å…¥ä¸é…ç½®")
        
        use_sample = st.checkbox("ğŸ“± ä½¿ç”¨ç¤ºä¾‹è§†é¢‘", value=True)
        uploaded_file = None
        if not use_sample:
            uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šä¼  MP4 è§†é¢‘", type=["mp4"])
        
        st.markdown("### ğŸ§  Prompt ")
        with st.container(border=True, height=400):
            if "current_prompt" not in st.session_state:
                st.session_state.current_prompt = default_prompt

            edited_prompt = st.text_area(
                '',
                value=st.session_state.current_prompt,  # æ˜¾ç¤ºå½“å‰å·²ç¡®è®¤çš„ prompt
                height=300,
                help="å¿…é¡»åŒ…å« {timeline_text} å ä½ç¬¦ï¼Œå¦åˆ™æ— æ³•ä½¿ç”¨"
            )
            if st.button("âœ… ç¡®è®¤æ›´æ–° Prompt"):
                if "{timeline_text}" not in edited_prompt:
                    # æ ¡éªŒå¤±è´¥ï¼šæ˜¾ç¤ºé”™è¯¯æç¤ºï¼Œä¸æ›´æ–°
                    st.error("âŒ ä¿®æ”¹å¤±è´¥ï¼šPrompt ä¸­å¿…é¡»åŒ…å« `{timeline_text}` å ä½ç¬¦ï¼")
                else:
                    # æ ¡éªŒæˆåŠŸï¼šä¿å­˜å¹¶æç¤º
                    st.session_state.current_prompt = edited_prompt
                    st.toast("âœ… Prompt å·²æˆåŠŸæ›´æ–°ï¼", icon="ğŸ‰")
            
        analysis_mode = st.selectbox(
            "ğŸ” åˆ†ææ¨¡å¼",
            options=["å¿«é€Ÿæ‘˜è¦", "å…¨é¢åˆ†æ", "å®¡æ ¸æ¨¡å¼", "è‡ªå®šä¹‰"],
            index=1,
            help="å¿«é€Ÿæ‘˜è¦:ä½å»¶è¿Ÿï¼›å…¨é¢åˆ†æ:å¹³è¡¡æ•ˆæœï¼›å®¡æ ¸æ¨¡å¼:é«˜ç²¾åº¦+å®‰å…¨æ£€æµ‹"
        )
        # ğŸ‘‡ ä»…åœ¨è‡ªå®šä¹‰æ¨¡å¼
        if analysis_mode == "è‡ªå®šä¹‰":
            st.markdown("âš™ï¸ è‡ªå®šä¹‰å‚æ•°(ä»… UI å±•ç¤º,å®é™…ç”±åç«¯ä½¿ç”¨)")
            user_sim_threshold = st.slider("æ–‡æœ¬ç›¸ä¼¼åº¦é˜ˆå€¼", 0.7, 1.0, 0.92, 0.01)    
            user_time_gap_merge = st.slider("åˆå¹¶æ—¶é—´é—´éš”(ç§’)", 3, 10, 6, 1)
            user_interval_sec = st.slider("æŠ½å¸§é—´éš”", 1, 10, 5, 1)

        st.markdown("ğŸ§  å¤§æ¨¡å‹é€‰æ‹©")
        model_options = {
                "Qwen-Turboï¼ˆå¿«é€Ÿ/ä½æˆæœ¬ï¼‰": "qwen-turbo",
                "Qwen-Plusï¼ˆå‡è¡¡ï¼‰": "qwen-plus",
                "Qwen-Maxï¼ˆæœ€å¼º/é«˜ç²¾åº¦ï¼‰": "qwen-max",
        }
        selected_model_label = st.selectbox(
                "é€‰æ‹©æ¨ç†æ¨¡å‹",
                options=list(model_options.keys()),
                index=1,
                help="è‡ªå®šä¹‰æ¨¡å¼ä¸‹å¯è‡ªç”±é€‰æ‹©åº•å±‚å¤§æ¨¡å‹"
            )
        selected_model = model_options[selected_model_label]

# --- ä¸­é—´:è§†é¢‘é¢„è§ˆ ---
with col_middle:
    with st.container(border=True, height=800):
        st.subheader("ğŸ“º è§†é¢‘é¢„è§ˆ")
        
        video_source = None
        if use_sample:
            sample_path = "sample_videos/ä½“è‚²æ–°é—»çƒ­ç‚¹.mp4"
            if Path(sample_path).exists():
                video_source = sample_path
            else:
                st.warning("âŒ ç¤ºä¾‹è§†é¢‘æœªæ‰¾åˆ°,è¯·ä¸Šä¼ æˆ–æ£€æŸ¥ sample_videos/ ç›®å½•")
        elif uploaded_file:
            video_source = uploaded_file
        
        if video_source:
            st.video(video_source, format="video/mp4")
        else:
            st.info("è¯·é€‰æ‹©è§†é¢‘æº")


# --- å³ä¾§:åˆ†æç»“æœåŒº(ä¸€ä½“åŒ–æµå¼å±•ç¤º)---
with col_right:
    result_container = st.container(height=800, border=True)
    
    with result_container:
        st.subheader("ğŸ“Š åˆ†æç»“æœ")
        
        if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True):
            mode_config = get_analysis_mode_config(analysis_mode)
            if analysis_mode == "è‡ªå®šä¹‰":
                actual_sim = user_sim_threshold
                actual_gap = user_time_gap_merge
                interval_sec = user_interval_sec
            else:
                actual_sim = mode_config["sim_threshold"]
                actual_gap = mode_config["time_gap_merge"]
                interval_sec = mode_config["interval_sec"]
            
            status_text = st.empty()
            progress_bar = st.progress(0)
            
            try:
                # === é˜¶æ®µ 1: å‡†å¤‡è§†é¢‘ ===
                status_text.text("â³ å‡†å¤‡è§†é¢‘...")
                progress_bar.progress(10)
                
                if use_sample:
                    video_path = "sample_videos/ä½“è‚²æ–°é—»çƒ­ç‚¹.mp4"
                    if not Path(video_path).exists():
                        raise FileNotFoundError("ç¤ºä¾‹è§†é¢‘ä¸å­˜åœ¨,è¯·æ£€æŸ¥ sample_videos/ ç›®å½•")
                else:
                    if not uploaded_file:
                        raise ValueError("è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶")
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
                        tmp.write(uploaded_file.read())
                        video_path = tmp.name
                
                # === é˜¶æ®µ 2: æŠ½å¸§ & OCR ===
                status_text.text("ğŸ“¸ æŠ½å¸§ä¸­...")
                progress_bar.progress(30)
                frame_dir = tempfile.mkdtemp()
                frames = extract_frames(video_path, frame_dir, interval_sec)
               
                
                status_text.text("ğŸ”¤ OCR è¯†åˆ«ä¸­...")
                progress_bar.progress(50)
                ocr_raw = run_ocr(frames)
                ocr_cleaned = denoise_ocr(ocr_raw, conf_threshold=0.75)
                
                # === é˜¶æ®µ 3: åˆå¹¶æ–‡æœ¬ ===
                status_text.text("ğŸ§© åˆå¹¶æ–‡æœ¬ç‰‡æ®µ...")
                progress_bar.progress(70)

                final_segments = merge_text_across_frames_for_understanding(
                    ocr_cleaned,
                    sim_threshold=actual_sim,
                    time_gap_merge=actual_gap
                )
                # === æ„é€ æœ€ç»ˆ Prompt(å…³é”®:ä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„ prompt)===

                timeline_text = build_timeline(final_segments)

                final_prompt = build_prompt(st.session_state.current_prompt,timeline_text=timeline_text)

                
                # === é˜¶æ®µ 4: è°ƒç”¨ LLM ===
                status_text.text("ğŸ§  è°ƒç”¨å¤§æ¨¡å‹ç”ŸæˆæŠ¥å‘Š...")
                progress_bar.progress(90)
                actual_model = selected_model  # â† ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹

                llm = LLMClient(
                    api_key=os.getenv('DASHSCOPE_API_KEY'),
                    api_url="https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
                    model_name=actual_model
                )
                result = llm.analyze(final_prompt)  # â† çœŸå®è°ƒç”¨
                # åœ¨ä½ çš„åˆ†æä»£ç ä¸­æ›¿æ¢æ—¥å¿—éƒ¨åˆ†
                try:
                    # æ„é€ çº¯å­—ç¬¦ä¸²æ—¥å¿—ï¼ˆå®‰å…¨ï¼ï¼‰
                    log_msg = (
                        f"\n-------------------------------- [{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] --------------------------\n"
                        f"----------------Full Prompt:---------------\n{st.session_state.current_prompt}\n"
                        f"----------------TimelineText:-------------\n{timeline_text}\n"
                        f"Model: {actual_model}\n"
           
                        f"Result preview: {str(result)[:500]}\n"
                        f"{'-'*50}\n"
                    )
                    
                    # ç›´æ¥å†™å…¥æ–‡ä»¶ï¼ˆä¸ä¾èµ– logging æ¨¡å—ï¼‰
                    with open(f"logs/analysis_{datetime.now().strftime('%Y%m%d')}.log", "a", encoding="utf-8") as f:
                        f.write(log_msg)
                    
                    st.toast("âœ… åˆ†ææ—¥å¿—å·²ä¿å­˜ï¼", icon="ğŸ“")

                except Exception as e:
                    st.error(f"âŒ æ—¥å¿—ä¿å­˜å¤±è´¥: {e}")
                    # å¼ºåˆ¶è®°å½•é”™è¯¯
                    with open("logs/error.log", "a") as f:
                        f.write(f"{datetime.now()}: {e}\n")
                progress_bar.progress(100)#è¿›åº¦æ¡
                time.sleep(0.2)
                status_text.empty()
                progress_bar.empty()
                
                # ==============================
                # å¯æŠ˜å æ˜¾ç¤ºåŸå§‹ result å†…å®¹
                # ==============================
                with st.expander("ğŸ” æŸ¥çœ‹LLMåˆ†æç»“æœ"):
                    st.json(result)  # ä»¥æ ¼å¼åŒ– JSON æ˜¾ç¤ºï¼Œç¾è§‚ä¸”å¯è¯»
                    # æˆ–è€…ç”¨ st.write(result) ä¹Ÿå¯ä»¥ï¼Œä½† st.json æ›´é€‚åˆå­—å…¸ç»“æ„
                # æ‘˜è¦ + ç½®ä¿¡åº¦
                st.markdown("##### ğŸ“ è‡ªåŠ¨æ‘˜è¦")
                st.write(result.get("summary", "æœªè¿”å›æ‘˜è¦"))
                conf = result.get("summary_confidence", 0.85)
                st.markdown(
                    f'<div style="height:6px; background:#e2e8f0; border-radius:3px; margin:8px 0;">'
                    f'<div style="height:100%; width:{conf*100}%; background:#3b82f6; border-radius:3px;"></div>'
                    f'</div>',
                    unsafe_allow_html=True
                )
                st.caption(f"ç½®ä¿¡åº¦:{conf:.0%}")
                st.divider()
                
                # æ ‡ç­¾
                tags = result.get("tags", [])
                if tags:
                    tag_badges = "".join([
                        f'<span style="display:inline-block; background:#dbeafe; color:#1d4ed8; '
                        f'padding:4px 12px; border-radius:20px; margin:0 6px 6px 0; font-size:0.85em;">'
                        f'{tag}</span>'
                        for tag in tags
                    ])
                    st.markdown("##### ğŸ·ï¸ å…³é”®è¯æ ‡ç­¾")
                    st.markdown(tag_badges, unsafe_allow_html=True)
                    st.divider()
                
                feature_labels = {
                    "category": "åˆ†ç±»",
                    "genre": "ä½“è£",
                    "tone": "è°ƒæ€§",
                    "sentiment": "æƒ…æ„Ÿå€¾å‘",
                    "is_low_quality": "æ˜¯å¦ä¸ºä½è´¨å†…å®¹",
                    "has_risk": "æ˜¯å¦æ½œåœ¨è¿è§„é£é™©",
                }

                # ç”¨äºå­˜å‚¨æœ€ç»ˆè¦æ˜¾ç¤ºçš„ (æ ‡ç­¾, å€¼) å¯¹
                display_items = []

                # 1. å¤„ç†å·²çŸ¥å­—æ®µï¼ˆæŒ‰ feature_labels é¡ºåºï¼Œä¿è¯ UI ç¨³å®šï¼‰
                for key, label in feature_labels.items():
                    if key in result and result[key] not in (None, ""):
                        value = result[key]
                        # å¦‚æœæ˜¯å¸ƒå°”å€¼ï¼Œè½¬ä¸ºâ€œæ˜¯/å¦â€
                        if isinstance(value, bool):
                            value = "æ˜¯" if value else "å¦"
                        else:
                            value = str(value)
                        display_items.append((label, value))

                # 2. å¤„ç†æœªçŸ¥å­—æ®µï¼ˆä¸åœ¨ feature_labels ä¸­çš„ï¼‰
                for key, value in result.items():
                    if key not in feature_labels and key not in ("summary","summary_confidence", "tags"):  # æ’é™¤ summary/tags ç­‰ä¸»å­—æ®µ
                        if value is not None and value != "":
                            # ç®€å•ç¾åŒ–å­—æ®µåï¼šå¦‚ "extra_field" â†’ "Extra Field"
                            pretty_key = key.replace("_", " ").capitalize()
                            if isinstance(value, bool):
                                value = "æ˜¯" if value else "å¦"
                            else:
                                value = str(value)
                            display_items.append((pretty_key, value))

                # 3. æ¸²æŸ“
                if display_items:
                    st.markdown("##### ğŸ¯ å†…å®¹ç‰¹å¾")
                    for label, value in display_items:
                        st.markdown(f"**{label}**ï¼š{value}")
                    st.divider()
                # å®‰å…¨æ£€æµ‹
                st.markdown("##### âš ï¸ å®‰å…¨æ£€æµ‹")
                risk_level = result.get("risk_level", "ä½")
                risk_color = {"ä½": "#4ade80", "ä¸­": "#fbbf24", "é«˜": "#ef4444"}.get(risk_level, "#9ca3af")
                st.markdown(
                    f'<span style="display:inline-block; background:{risk_color}20; color:{risk_color}; '
                    f'padding:4px 12px; border-radius:20px; font-weight:500;">'
                    f'è¿è§„é£é™©:{risk_level}</span>',
                    unsafe_allow_html=True
                )
                sensitive_words = result.get("sensitive_words", [])
                if sensitive_words:
                    st.write("æ•æ„Ÿè¯:" + ", ".join(sensitive_words))
                else:
                    st.info("æœªæ£€æµ‹åˆ°æ•æ„Ÿå†…å®¹")
                st.divider()

                
                # # ç”¨æˆ·åé¦ˆ
                # st.markdown("ğŸ’¬ **ç»“æœåé¦ˆ**")
                # cols = st.columns(3)
                # with cols[0]:
                #     if st.button("æ‘˜è¦ä¸å‡†", key="fb1"):
                #         st.toast("æ„Ÿè°¢åé¦ˆï¼æˆ‘ä»¬å°†ä¼˜åŒ–æ‘˜è¦æ¨¡å‹ã€‚")
                # with cols[1]:
                #     if st.button("æ ‡ç­¾ä¸ç›¸å…³", key="fb2"):
                #         st.toast("æ„Ÿè°¢åé¦ˆï¼æ ‡ç­¾ç³»ç»Ÿå°†è¿›è¡Œè¿­ä»£ã€‚")
                # with cols[2]:
                #     if st.button("å…¶ä»–é—®é¢˜", key="fb3"):
                #         st.toast("è¯·é€šè¿‡å†…éƒ¨æ¸ é“æäº¤è¯¦ç»†åé¦ˆã€‚")
            
            except Exception as e:
                status_text.empty()
                progress_bar.empty()
                st.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
                # ç”Ÿäº§ç¯å¢ƒå»ºè®®è®°å½•æ—¥å¿—,è€Œéæ˜¾ç¤º traceback
                # logger.error("Analysis failed", exc_info=True)


# ====== é¡µè„š ======
st.markdown("---")
st.caption("Â© 2025 è§†é¢‘æ™ºèƒ½åˆ†æå¹³å° | åŸºäº PaddleOCR + Qwen | æ•°æ®ä¸å‡ºåŸŸ Â· å®‰å…¨åˆè§„")